{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rentop Kaggle Competition\n",
    "\n",
    "W207-3 Spring 2017\n",
    "\n",
    "Team members: Stephanie Fan, Boris Kletser, Amitabha Karmakar \n",
    "\n",
    "**Goal:** Use rental listing features to predict interest in rental inquiries.\n",
    "\n",
    "- [Kaggle Competition](https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries)\n",
    "- [Notebooks and Code](https://github.com/letslego/Rentop/)\n",
    "\n",
    "For final code, refer to RentHop_Code.ipynb, which is annotated with the appropriate sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** The problem we are trying to solve is two-fold: First, it is to provide feedback to owners and agents on how to optimize listings to generate interest. Secondly, it helps RentHop identify potential issues with listings and fraud. Both of these should help customers better identify relevant listings.\n",
    "\n",
    "**Metrics:** The relevant metric is accurate prediction of high, medium, and low interest. \n",
    "We would like to increase accuracy to 80% correct identification of high, medium, or low interest.\n",
    "\n",
    "**Delivery:** We will deliver a model that predicts the probability of high, medium, and low interest for a given listing.\n",
    "\n",
    "*Note:* For the purposes of this assignment, we will not be doing analysis of images provided with the competition and will mainly be focusing on using existing features (e.g. text, and values) to try to predict interest level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources:**\n",
    "- train.json:  49352 records over 15 columns\n",
    "- test.json:   74659 records over 14 columns\n",
    "\n",
    "Each row is a listing; each column is a feature. The extra column in train.json is the interest level, which we need to predict for test.json."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Existing Features:**\n",
    "    \n",
    "|Feature Type|Columns|Type|Notes|\n",
    "|---|---|---|---|\n",
    "|IDs|building_id|Long string||\n",
    "||listing_id|7 digit num||\n",
    "||manager_id|Long string||\n",
    "|Location|street_address|Text||\n",
    "||display_address|Text||\n",
    "||latitude|Float|New York City only|\n",
    "||longitude|Float|New York City only|\n",
    "|Features|bathrooms|Int|(mean 1.2, sd 0.5)|\n",
    "||bedrooms|Int|(mean 1.5, sd 1.1)|\n",
    "||descriptions|Text||\n",
    "||price|Int||\n",
    "||created|Date|Dates between 2016-04 and 2016-06. Spread throughout weeks, mostly between 1-5am (esp 2am)\n",
    "||photos|List of URLs||\n",
    "|Target Var|interest_level|High/Medium/Low|This is what weâ€™re predicting|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of features\n",
    "||bathrooms|bedrooms|latitude|longitude|price|\n",
    "|---|---|---|---|---|---|\n",
    "|count|49352|49352|49352|49352|49352|\n",
    "|mean|1.21218|1.541640|40.741545|-73.955716|3830.174|\n",
    "|std|0.50142|1.115018|0.638535|1.177912|22,066.87|\n",
    "|min|0|0|0|-118.271000|43.00|\n",
    "|25%|1|1|40.7283|-73.9917|2,500.00|\n",
    "|50%|1|1|40.7518|-73.9779|3,150.00|\n",
    "|75%|1|2|40.7743|-73.9548|4,100.00|\n",
    "|max|10|8|44.8835|0.0000|4,490,000.00|\n",
    "\n",
    "There is a skew in the number of bathrooms, bedrooms, and price, with the majority of the values being on the low end with a few high outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values\n",
    "Based on the data distribution, there are some missing values (e.g. 0 for the longitutde), but all values in the table are filled in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of target\n",
    "The distribution of the target is severly biased toward the low interest class. Approximately 71%, 23%, and 7% of the dataset fall into the low, medium, and high interest level classes, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationships between features\n",
    "\n",
    "||bathrooms|bedrooms|latitude|longitude|price|\n",
    "|---|---|---|---|---|---|\n",
    "|bathrooms|1.000000|0.533446|-0.009657|0.010393|0.069661|\n",
    "|bedrooms|0.533446|1.000000|-0.004745|0.006892|0.051788|\n",
    "|latitude|-0.009657|-0.004745|1.000000|-0.966807|-0.000707|\n",
    "|longitude|0.010393|0.006892|-0.966807|1.000000|-0.000087|\n",
    "|price|0.069661|0.051788|-0.000707|-0.000087|1.000000|\n",
    "\n",
    "Unsurprisingly, there is a slight correlation between the number of bedrooms and the number of bathrooms. This is expected because houses are built with roughly a proportional number of bathrooms to the number of bedrooms in a house. Longitude and latitude are also quite correlated, although this could be due to the outliers in the dataset (suspected incorrect values because there are some significantly different values, and this dataset only has data from New York). Otherwise, latitude and longitude fall within a very small are of New York City. If you view the neighborhood clusters in the code notebook, you can see that the geolocation falls largely into a diagonal line due to the shape of the area we are looking at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformation and Engineering\n",
    "*[De-duplicating features](https://www.kaggle.com/jxnlco/two-sigma-connect-rental-listing-inquiries/deduplicating-features)*: parses descriptions into consistent rental features (ex: 24-hr concierge) and replaces synonyms with consistent terminology\n",
    "\n",
    "*Text analysis:* Split descriptions into features describing writing style\n",
    "- length of description\n",
    "- number of words\n",
    "- number of capital letters used\n",
    "- number of punctuation marks used\n",
    "- vocabulary richness (use of unique words)\n",
    "\n",
    "*Feature Aggregation & Transformation*: Combine existing features into other features\n",
    "- price per bedroom\n",
    "- price per bathroom\n",
    "- price per room\n",
    "- number of photos per listing\n",
    "- number of claimed rental features\n",
    "- difference between street and display addresses\n",
    "- neighborhoods (based on latitude/longitude)\n",
    "- Multinomial Naive Bayes scoring for description vs interest level\n",
    "- Multinomial Naive Bayes scoring for features vs interest level\n",
    "\n",
    "*Time:* Split features into different time measurements -- does putting up the post at a certain time impact interest?\n",
    "- year (no impact as all rentals were from 2016)\n",
    "- month\n",
    "- day of the month\n",
    "- day of the week\n",
    "- hour\n",
    "- minute\n",
    "- second\n",
    "- time (hr + minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal component analysis (PCA)\n",
    "Features were regularized and un-correlated using PCA after all feature engineering had been performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Transformation\n",
    "Transform target (interest level = high, medium, or low) into ordinal values\n",
    "- high = 2\n",
    "- medium = 1\n",
    "- low = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final model:** Random Forest Classifier\n",
    "\n",
    "*Assumptions:* Features are non-parametric. We picked this method as it is fairly robust and does not require data to be parametric or regularized. In addition, using this method could allow for real-world interpretation of answers in comparison to other models, leading to the potential for guidelines for posters to enhance attractiveness. \n",
    "\n",
    "*Regularization:* none. Not needed due to model type chosen.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other models tried:** \n",
    "\n",
    "|Model|Score|Notes|\n",
    "|---|---|---|\n",
    "|Baseline - linear regression against latitude and longitutde|0.79053|Surprisingly, this model was very quite good as it was based purely on location.|\n",
    "|Multinomial Naive Bayes with Tdidf vectorization of description|0.75440|This was the best model given the set of features and models we tried. It was surprising as we thought there would be better predictors.|\n",
    "|Random Forest on all numeric features after feature engineering|1.22052|There were not a huge number of numeric features (~29), so this model may not work as robustly as we expected.|\n",
    "|Random Forest on top numeric features|2.26920|We only entered the top three factors, which was inappropriate given this model type. Due to this, the diversity of the trees was probably not very large, and probably biased the predictions.|\n",
    "|Linear regression with all numeric features|1.09215|The linear regression gave a better result than the random forest model, likely due to the smaller number of features.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained using accuracy as a metric, and then periodic submissions were made to the Kaggle competition, which scores use the log loss function.\n",
    "\n",
    "Overall, the models did not perform very well. In training the model based on accuracy, we generally only were able to predict the development set at around a 70% accuracy level given the features we had selected. This suggested that there may be some other factors that were not present in the dataset. A couple of factors that readily spring to mind that were unaccounted for was visual attractiveness of the photos, and user demographics as apartment rentals are driven by the need of the user, which can vary greatly depending on the point they are at in the life (e.g. young professionals, young families, age and number of children, student, seniors, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Next Steps\n",
    "If we were continuing this competition, we would consider looking at the following next:\n",
    "\n",
    "|Item|Rationale|\n",
    "|---|---|\n",
    "|Image Processing|Humans are highly visual, and we chose not to pursue image processing as part of the competition. However, we recognize the impact that photos can have, and believe this would be a worthwhile area to explore for features. Some top-of-mind ideas are brightness and contrast of the images, resolution, and size.|\n",
    "|User Clustering|Another model that could be persued is to evaluate clusters within each interest level to see what clusters of features are attractive. This could help posters gain a better understanding of potential renters and what they are looking for.|\n",
    "|Deep Learning|We settled on using Random Forests because it was a relatively easy method to employ. However, we cannot always understand how people work on a topical level. Additionally, we had a somewhat large set of features, which deep learning requires in order to be worthwhile.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
