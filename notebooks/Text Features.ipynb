{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_active": false,
    "_cell_guid": "ca50d942-809f-21d9-aa30-7f4eb60999b3",
    "collapsed": false
   },
   "source": [
    "# Text Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "_active": false,
    "_cell_guid": "cca36417-3de2-c57d-8616-10a6f0e65574",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.naive_bayes import BernoulliNB\n",
    "#from sklearn.naive_bayesf import MultinomialNB\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import itemfreq\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "_active": false,
    "_cell_guid": "e98c7c95-b212-5060-ca03-d067e387fab8",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\"../input/train.json\")\n",
    "test_df = pd.read_json(\"../input/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = train_df['interest_level']\n",
    "y2 = y.replace({'low':1,'medium':2,'high':3})\n",
    "\n",
    "X = train_df.drop('interest_level', 1)\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y2, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "#using dif var in case user wants to keep original df.\n",
    "def add_txt_features(orig):\n",
    "    dat = orig\n",
    "    dat.loc[:,'strlen'] = [len(x) for x in dat['description']] #can ignore warnings because making new column\n",
    "    dat.loc[:,'numwords'] = [len(x.split()) for x in dat['description']]\n",
    "    dat.loc[:,'numcaps'] = [sum(1 for c in x if c.upper()) for x in dat['description']]\n",
    "    dat.loc[:,'numpunct'] = [sum(1 for c in x if c in punctuation) for x in dat['description']]\n",
    "    dat.loc[:,'richness'] = [len(set(x)) / (len(x)+0.001) for x in dat['description']]\n",
    "    return dat\n",
    "\n",
    "X_train = add_txt_features(X_train)\n",
    "X_dev =   add_txt_features(X_dev)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 95.16%\n",
      "Training Score: 68.36%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train_limited = X_train[['strlen','numwords','numcaps','numpunct','richness']]\n",
    "X_dev_limited = X_dev[['strlen','numwords','numcaps','numpunct','richness']]\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1) #-1 means use all available cores\n",
    "rfc.fit(X_train_limited, y_train)\n",
    "\n",
    "print('Training Score: %.2f%%' % (rfc.score(X_train_limited, y_train) * 100))\n",
    "print('Training Score: %.2f%%' % (rfc.score(X_dev_limited, y_dev) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "_active": true,
    "_cell_guid": "305f5c90-23ec-9aa0-5e8c-f1fa1295b0e5",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['richness', 'numwords', 'numcaps', 'strlen', 'numpunct']\n",
      "[ 0.2594755   0.19082518  0.18518305  0.18305032  0.18146596]\n"
     ]
    }
   ],
   "source": [
    "importances = rfc.feature_importances_\n",
    "features = X_train_limited.columns\n",
    "\n",
    "sort_indices = np.argsort(importances)[::-1]\n",
    "sorted_features = []\n",
    "for i in sort_indices:\n",
    "    sorted_features.append(features[i])\n",
    "\n",
    "print(sorted_features)\n",
    "print importances[sort_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a look at # photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Accuracy: 69.62% \t Test Accuracy: 68.85%\n"
     ]
    }
   ],
   "source": [
    "#pd.options.display.max_colwidth = 1000\n",
    "pd.options.display.max_colwidth = 50\n",
    "\n",
    "def get_num_photos(orig):\n",
    "    dat = orig\n",
    "    dat.loc[:,'numphotos'] = [len(x) for x in dat['photos'].values]\n",
    "    return dat\n",
    "\n",
    "X_train = get_num_photos(X_train)\n",
    "X_dev =   get_num_photos(X_dev)\n",
    "\n",
    "X_train_ph = X_train[['numphotos']]\n",
    "X_dev_ph = X_dev[['numphotos']]\n",
    "\n",
    "#print X_train_ph.head()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_ph, y_train)\n",
    "\n",
    "print('\\t Training Accuracy: %.2f%% \\t Test Accuracy: %.2f%%' % (lr.score(X_train_ph, y_train)*100, \n",
    "                                                                 lr.score(X_dev_ph, y_dev)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words, Photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 95.78% \t Training Score: 68.95%\n",
      "['richness', 'strlen', 'numcaps', 'numwords', 'numpunct', 'numphotos']\n",
      "[ 0.21972227  0.16989367  0.16817354  0.1681099   0.1588827   0.11521791]\n"
     ]
    }
   ],
   "source": [
    "X_train_combo = X_train[['strlen','numwords','numcaps','numpunct','richness','numphotos']]\n",
    "X_dev_combo = X_dev[['strlen','numwords','numcaps','numpunct','richness','numphotos']]\n",
    "\n",
    "rfc2 = RandomForestClassifier(n_estimators=100, n_jobs=-1) #-1 means use all available cores\n",
    "rfc2.fit(X_train_combo, y_train)\n",
    "\n",
    "print('Training Score: %.2f%% \\t Training Score: %.2f%%' % (\n",
    "        rfc2.score(X_train_combo, y_train) * 100,\n",
    "        rfc2.score(X_dev_combo, y_dev) * 100))\n",
    "\n",
    "importances = rfc2.feature_importances_\n",
    "features = X_train_combo.columns\n",
    "\n",
    "sort_indices = np.argsort(importances)[::-1]\n",
    "sorted_features = []\n",
    "for i in sort_indices:\n",
    "    sorted_features.append(features[i])\n",
    "\n",
    "print(sorted_features)\n",
    "print importances[sort_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add in to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Accuracy: 69.62% \t Test Accuracy: 68.86%\n"
     ]
    }
   ],
   "source": [
    "def get_num_features(orig):\n",
    "    dat = orig\n",
    "    dat.loc[:,'numfeatures'] = [len(x) for x in dat['features'].values]\n",
    "    return dat\n",
    "\n",
    "X_train = get_num_features(X_train)\n",
    "X_dev = get_num_features(X_dev)\n",
    "\n",
    "X_train_f = X_train[['numfeatures']]\n",
    "X_dev_f = X_dev[['numfeatures']]\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_f, y_train)\n",
    "\n",
    "print('\\t Training Accuracy: %.2f%% \\t Test Accuracy: %.2f%%' % (lr.score(X_train_f, y_train)*100, \n",
    "                                                                 lr.score(X_dev_f, y_dev)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about comparing addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR \t Training Accuracy: 69.58% \t Dev Accuracy: 69.23%\n"
     ]
    }
   ],
   "source": [
    "def get_address_combo(orig):\n",
    "    dat = orig\n",
    "    dat.loc[:,'numfeatures'] = [len(x) for x in dat['features'].values]\n",
    "    return dat\n",
    "\n",
    "################## rewriting in progress ################## bb1:20170420\n",
    "\n",
    "sa_len = [len(sa) for sa in X_train['street_address']]\n",
    "da_len = [len(da) for da in X_train['display_address']]\n",
    "dif_len = np.subtract(sa_len,da_len)\n",
    "\n",
    "dd_t = pd.DataFrame()\n",
    "dd_t['dif_len'] = dif_len\n",
    "\n",
    "sa_len_dev = [len(sa) for sa in X_dev['street_address']]\n",
    "da_len_dev = [len(da) for da in X_dev['display_address']]\n",
    "dif_len_dev = np.subtract(sa_len_dev,da_len_dev)\n",
    "\n",
    "\n",
    "dd_d = pd.DataFrame()\n",
    "dd_d['dif_len'] = dif_len_dev\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(dd_t, y_train)\n",
    "\n",
    "print('LR \\t Training Accuracy: %.2f%% \\t Dev Accuracy: %.2f%%' % (lr.score(dd_t, y_train)*100, \n",
    "                                                                 lr.score(dd_d, y_dev)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF\tTraining Score:94.15%        \tDev Score: 67.10%\n",
      "LR \t Training Accuracy: 69.53% \t Dev Accuracy: 69.15%\n",
      "['richness', 'numcaps', 'strlen', 'numwords', 'numpunct', 'num_photos']\n",
      "[ 0.21859142  0.17003016  0.16858574  0.1677809   0.16266951  0.11234227]\n"
     ]
    }
   ],
   "source": [
    "ddf_tr['num_photos'] = num_photos\n",
    "ddf_de['num_photos'] = num_photos_dev\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, n_jobs=-1) #-1 means use all available cores\n",
    "rfc.fit(ddf_tr, y_train)\n",
    "print('\\nRF\\tTraining Score:%.2f%% \\\n",
    "       \\tDev Score: %.2f%%' % (rfc.score(ddf_tr, y_train) * 100, rfc.score(ddf_de, y_dev) * 100))\n",
    "\n",
    "\n",
    "importances = rfc.feature_importances_\n",
    "features = ddf_tr.columns\n",
    "\n",
    "sort_indices = np.argsort(importances)[::-1]\n",
    "sorted_features = []\n",
    "for i in sort_indices:\n",
    "    sorted_features.append(features[i])\n",
    "\n",
    "vals = importances[sort_indices]\n",
    "labels = sorted_features\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(ddf_tr, y_train)\n",
    "print('LR \\t Training Accuracy: %.2f%% \\t Dev Accuracy: %.2f%%' % (lr.score(ddf_tr, y_train)*100, \n",
    "                                                                 lr.score(ddf_de, y_dev)*100))\n",
    "\n",
    "\n",
    "\n",
    "print labels\n",
    "print vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF\tTraining Score:94.15%        \tDev Score: 67.10%\n",
      "LR \t Training Accuracy: 69.53% \t Dev Accuracy: 69.15%\n",
      "['richness', 'numcaps', 'strlen', 'numwords', 'numpunct', 'num_photos']\n",
      "[ 0.21859142  0.17003016  0.16858574  0.1677809   0.16266951  0.11234227]\n"
     ]
    }
   ],
   "source": [
    "ddf_tr['num_photos'] = num_photos\n",
    "ddf_de['num_photos'] = num_photos_dev\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, n_jobs=-1) #-1 means use all available cores\n",
    "rfc.fit(ddf_tr, y_train)\n",
    "print('\\nRF\\tTraining Score:%.2f%% \\\n",
    "       \\tDev Score: %.2f%%' % (rfc.score(ddf_tr, y_train) * 100, rfc.score(ddf_de, y_dev) * 100))\n",
    "\n",
    "\n",
    "importances = rfc.feature_importances_\n",
    "features = ddf_tr.columns\n",
    "\n",
    "sort_indices = np.argsort(importances)[::-1]\n",
    "sorted_features = []\n",
    "for i in sort_indices:\n",
    "    sorted_features.append(features[i])\n",
    "\n",
    "vals = importances[sort_indices]\n",
    "labels = sorted_features\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(ddf_tr, y_train)\n",
    "print('LR \\t Training Accuracy: %.2f%% \\t Dev Accuracy: %.2f%%' % (lr.score(ddf_tr, y_train)*100, \n",
    "                                                                 lr.score(ddf_de, y_dev)*100))\n",
    "\n",
    "\n",
    "\n",
    "print labels\n",
    "print vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF\tTraining Score:94.15%        \tDev Score: 67.10%\n",
      "LR \t Training Accuracy: 69.53% \t Dev Accuracy: 69.15%\n",
      "['richness', 'numcaps', 'strlen', 'numwords', 'numpunct', 'num_photos']\n",
      "[ 0.21859142  0.17003016  0.16858574  0.1677809   0.16266951  0.11234227]\n"
     ]
    }
   ],
   "source": [
    "ddf_tr['num_photos'] = num_photos\n",
    "ddf_de['num_photos'] = num_photos_dev\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, n_jobs=-1) #-1 means use all available cores\n",
    "rfc.fit(ddf_tr, y_train)\n",
    "print('\\nRF\\tTraining Score:%.2f%% \\\n",
    "       \\tDev Score: %.2f%%' % (rfc.score(ddf_tr, y_train) * 100, rfc.score(ddf_de, y_dev) * 100))\n",
    "\n",
    "\n",
    "importances = rfc.feature_importances_\n",
    "features = ddf_tr.columns\n",
    "\n",
    "sort_indices = np.argsort(importances)[::-1]\n",
    "sorted_features = []\n",
    "for i in sort_indices:\n",
    "    sorted_features.append(features[i])\n",
    "\n",
    "vals = importances[sort_indices]\n",
    "labels = sorted_features\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(ddf_tr, y_train)\n",
    "print('LR \\t Training Accuracy: %.2f%% \\t Dev Accuracy: %.2f%%' % (lr.score(ddf_tr, y_train)*100, \n",
    "                                                                 lr.score(ddf_de, y_dev)*100))\n",
    "\n",
    "\n",
    "\n",
    "print labels\n",
    "print vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add in address dif to bigger set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF\tTraining Score:94.88%        \tDev Score: 67.85%\n",
      "LR \t Training Accuracy: 69.53% \t Dev Accuracy: 69.17%\n",
      "['richness', 'strlen', 'numwords', 'numcaps', 'numpunct', 'num_features', 'num_photos', 'addr_diff']\n",
      "[ 0.16974545  0.1423083   0.14183043  0.14065956  0.13946252  0.10279839\n",
      "  0.10262046  0.06057489]\n"
     ]
    }
   ],
   "source": [
    "ddf_tr['addr_diff'] = dif_len\n",
    "ddf_de['addr_diff'] = dif_len_dev\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, n_jobs=-1) #-1 means use all available cores\n",
    "rfc.fit(ddf_tr, y_train)\n",
    "print('\\nRF\\tTraining Score:%.2f%% \\\n",
    "       \\tDev Score: %.2f%%' % (rfc.score(ddf_tr, y_train) * 100, rfc.score(ddf_de, y_dev) * 100))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(ddf_tr, y_train)\n",
    "print('LR \\t Training Accuracy: %.2f%% \\t Dev Accuracy: %.2f%%' % (lr.score(ddf_tr, y_train)*100, \n",
    "                                                                 lr.score(ddf_de, y_dev)*100))\n",
    "\n",
    "importances = rfc.feature_importances_\n",
    "features = ddf_tr.columns\n",
    "\n",
    "sort_indices = np.argsort(importances)[::-1]\n",
    "sorted_features = []\n",
    "for i in sort_indices:\n",
    "    sorted_features.append(features[i])\n",
    "\n",
    "vals = importances[sort_indices]\n",
    "labels = sorted_features\n",
    "\n",
    "print labels\n",
    "print vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "(array([[ 0.63026916,  0.28405181,  0.08567904],\n",
      "       [ 0.75915932,  0.17011315,  0.07072753],\n",
      "       [ 0.74824329,  0.16984734,  0.08190937],\n",
      "       ..., \n",
      "       [ 0.71844147,  0.2064246 ,  0.07513394],\n",
      "       [ 0.66258059,  0.25896006,  0.07845935],\n",
      "       [ 0.73225698,  0.19140256,  0.07634047]]), (33065L, 3L))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-e9f4e8f702fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'low'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'medium'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'high'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmy_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "'''labels = lr.classes_\n",
    "print(labels)\n",
    "predictions = lr.predict_proba(ddf_tr)\n",
    "print(predictions, predictions.shape)\n",
    "\n",
    "indexes = ['low','medium','high']\n",
    "print(indexes)\n",
    "\n",
    "my_df = pd.DataFrame(data=predictions, index=indexes, columns=labels)  \n",
    "my_df.index.names = ['listing_id']\n",
    "\n",
    "cols = my_df.columns.tolist()\n",
    "print(cols)\n",
    "cols = [cols[2], cols[1], cols[0]]\n",
    "print(cols)\n",
    "\n",
    "print(my_df[cols])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
